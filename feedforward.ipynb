{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c47c029c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "#from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "nltk.download(\"punkt_tab\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e9c11bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"AmazonScience/massive\", \"fr-FR\")\n",
    "class_name = \"scenario\"\n",
    "\n",
    "\n",
    "X_train = ds[\"train\"][\"utt\"]\n",
    "Y_train = ds[\"train\"][class_name]\n",
    "X_test = ds[\"test\"][\"utt\"]\n",
    "Y_test = ds[\"test\"][class_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5baa8f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "h_dim = 100\n",
    "lr = 5e-4\n",
    "epochs = 10\n",
    "batch_size = 25\n",
    "\n",
    "activation_function = nn.functional.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "48f5ea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenized = [nltk.word_tokenize(x) for x in X_train]\n",
    "X_test_tokenized = [nltk.word_tokenize(x) for x in X_test]\n",
    "\n",
    "#Create the word corpus to create embeddings\n",
    "corpus = Counter(list(itertools.chain(*X_train_tokenized)))\n",
    "corpus = sorted(corpus,key=corpus.get,reverse=True) #[:1000]\n",
    "onehot_dict = {w:i+1 for i,w in enumerate(corpus)}\n",
    "\n",
    "#Create the embeddings\n",
    "X_train_embeddings = [[onehot_dict[word] for word in sentence] for sentence in X_train_tokenized]\n",
    "#We only add the test embeddings if they are in the vocab - this is an issue of the method, unknown words won't be able to have meaning\n",
    "#We could also give it an arbitrary value, to be tested\n",
    "X_test_embeddings = [[onehot_dict[word] if word in onehot_dict else len(onehot_dict) for word in sentence] for sentence in X_test_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc23f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding embedding vectors to max sentence length\n",
    "max_sentence_length = len(max(X_train_embeddings, key=len))\n",
    "X_train_padded = [np.pad(x, (0, max_sentence_length - len(x)), 'constant', constant_values=(0,0)) for x in X_train_embeddings]\n",
    "\n",
    "#truncate if needed before padding\n",
    "X_test_embeddings = [x[:max_sentence_length] for x in X_test_embeddings]\n",
    "X_test_padded = [np.pad(x, (0, max_sentence_length - len(x)), 'constant', constant_values=(0,0)) for x in X_test_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7f266e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9918/4167475810.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  train_data = TensorDataset(torch.tensor(X_train_padded), torch.tensor(Y_train))\n"
     ]
    }
   ],
   "source": [
    "#Load into Tensor format\n",
    "train_data = TensorDataset(torch.tensor(X_train_padded), torch.tensor(Y_train))\n",
    "test_data = TensorDataset(torch.tensor(X_test_padded), torch.tensor(Y_test))\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "train_iter = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd6b6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model definition\n",
    "class Feedforward(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, activation_function):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.activation_function = activation_function\n",
    "    \n",
    "    def forward(self, text):\n",
    "        hidden = self.fc1(text.float())\n",
    "        hidden = self.activation_function(hidden)\n",
    "\n",
    "        out = self.fc2(hidden)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956766c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optim, loss_fun, one_hot_encode=False):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for sentences, labels in dataloader:\n",
    "        if one_hot_encode:\n",
    "            sentences = nn.functional.one_hot(torch.LongTensor(sentences), num_classes=len(onehot_dict) + 1)\n",
    "            sentences = torch.FloatTensor(sentences)\n",
    "        optim.zero_grad()\n",
    "        outputs = model.forward(sentences)\n",
    "        loss = loss_fun(outputs, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81647991",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to evaluate a model's predictions. Returns (loss, accuracy)\n",
    "def evaluate(model, dataloader, loss_fun):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for sentences, labels in dataloader:\n",
    "        outputs = model.forward(sentences)\n",
    "        loss = loss_fun(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #Calculate correct predictions for this batch\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += len(predictions)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "022d5c00",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m optimizer = torch.optim.Adam(model_base.parameters(), lr=lr)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, optim, loss_fun)\u001b[39m\n\u001b[32m      6\u001b[39m outputs = model.forward(sentences)\n\u001b[32m      7\u001b[39m loss = loss_fun(outputs, labels)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m optim.step()\n\u001b[32m     11\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/nlp/venv/lib/python3.13/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/nlp/venv/lib/python3.13/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/nlp/venv/lib/python3.13/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "model_base = Feedforward(max_sentence_length, h_dim, 18, activation_function)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_base.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range (1, epochs + 1):\n",
    "    loss = train(model_base, train_loader, optimizer, loss_function)\n",
    "    print(f\"Epoch {epoch}: loss = {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f44fec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USING TD-IDF\n",
    "#tf-idf version of the encoding:\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = torch.Tensor(vectorizer.fit_transform(X_train).toarray())\n",
    "X_test_tfidf = torch.Tensor(vectorizer.transform(X_test).toarray())\n",
    "\n",
    "train_data_tfidf = TensorDataset(X_train_tfidf, torch.tensor(Y_train))\n",
    "test_data_tfidf = TensorDataset(X_test_tfidf, torch.tensor(Y_test))\n",
    "train_loader_tfidf = DataLoader(train_data_tfidf, shuffle=True, batch_size=batch_size)\n",
    "test_loader_tfidf = DataLoader(test_data_tfidf, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7aad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss = 2.3736631303961\n",
      "Epoch 2: loss = 1.2130047086779827\n",
      "Epoch 3: loss = 0.632274982048736\n",
      "Epoch 4: loss = 0.3952817688989019\n",
      "Epoch 5: loss = 0.27669062938969463\n",
      "Epoch 6: loss = 0.20648739082888254\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m optimizer_tfidf = torch.optim.Adam(model_tfidf.parameters(), lr=lr)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     loss = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_tfidf\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function_tfidf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, dataloader, optim, loss_fun)\u001b[39m\n\u001b[32m      5\u001b[39m optim.zero_grad()\n\u001b[32m      6\u001b[39m outputs = model.forward(sentences)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m loss = \u001b[43mloss_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m loss.backward()\n\u001b[32m      9\u001b[39m optim.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/nlp/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/nlp/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/nlp/venv/lib/python3.13/site-packages/torch/nn/modules/loss.py:1297\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/epita/nlp/venv/lib/python3.13/site-packages/torch/nn/functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#Train with tf-idf embeddings\n",
    "model_tfidf = Feedforward(X_train_tfidf.shape[1], h_dim, 18, activation_function)\n",
    "\n",
    "loss_function_tfidf = nn.CrossEntropyLoss()\n",
    "optimizer_tfidf = torch.optim.Adam(model_tfidf.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range (1, epochs + 1):\n",
    "    loss = train(model_tfidf, train_loader_tfidf ,optimizer_tfidf, loss_function_tfidf)\n",
    "    print(f\"Epoch {epoch}: loss = {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "19ff2c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with tf_idf: \n",
      "Loss = 0.10494832883623313, accuracy = 0.8863483523873571\n"
     ]
    }
   ],
   "source": [
    "loss_tfidf, accuracy_tfidf = evaluate(model_tfidf, test_loader_tfidf, loss_function_tfidf)\n",
    "print(f\"Evaluation with tf_idf: \\nLoss = {loss_tfidf}, accuracy = {accuracy_tfidf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63473eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Word2Vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[117]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#USING WORD2VEC\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m word2vec_encoder = \u001b[43mWord2Vec\u001b[49m(sentences=X_train_tokenized, vector_size=\u001b[32m100\u001b[39m, window=\u001b[32m5\u001b[39m, min_count=\u001b[32m1\u001b[39m, workers=\u001b[32m4\u001b[39m)\n\u001b[32m      4\u001b[39m X_train_data_word2vec = [np.mean([word2vec_encoder.wv[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m x \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word2vec_encoder.wv]) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_train_tokenized]\n",
      "\u001b[31mNameError\u001b[39m: name 'Word2Vec' is not defined"
     ]
    }
   ],
   "source": [
    "#USING WORD2VEC\n",
    "word2vec_encoder = Word2Vec(sentences=X_train_tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "X_train_data_word2vec = [np.mean([word2vec_encoder.wv[word] for word in x if word in word2vec_encoder.wv]) for x in X_train_tokenized]\n",
    "\n",
    "X_train_word2vec = torch.Tensor(X_train_data_word2vec)\n",
    "#X_test_word2vec = torch.Tensor()\n",
    "\n",
    "train_data_word2vec = TensorDataset(X_train_tfidf, torch.tensor(Y_train))\n",
    "#test_data_word2vec = TensorDataset(X_test_tfidf, torch.tensor(Y_test))\n",
    "train_loader_word2vec = DataLoader(train_data_tfidf, shuffle=True, batch_size=batch_size)\n",
    "#test_loader_word2vec = DataLoader(test_data_tfidf, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train with word2vec embeddings\n",
    "model_word2vec = Feedforward(100, h_dim, 18, activation_function)\n",
    "\n",
    "loss_function_word2vec = nn.CrossEntropyLoss()\n",
    "optimizer_word2vec = torch.optim.Adam(model_word2vec.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range (1, epochs + 1):\n",
    "    loss = train(model_word2vec, train_loader_word2vec ,optimizer_word2vec, loss_function_word2vec)\n",
    "    print(f\"Epoch {epoch}: loss = {loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "814fb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, bidirectional=False)\n",
    "        self.h2o = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, text):\n",
    "        rnn_output, hidden = self.rnn(text)\n",
    "        out = self.h2o(hidden)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b5ac3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data doing onehot encoding\n",
    "#X_train_onehots = nn.functional.one_hot(torch.LongTensor(X_train_padded))\n",
    "#X_test_onehots = nn.functional.one_hot(torch.LongTensor(X_test_padded))\n",
    "\n",
    "train_data_onehot = TensorDataset(torch.LongTensor(X_train_padded), torch.tensor(Y_train))\n",
    "#test_data_onehot = TensorDataset(X_test_onehots, torch.tensor(Y_test))\n",
    "train_loader_onehot = DataLoader(train_data_onehot, shuffle=True, batch_size=batch_size)\n",
    "#test_loader_onehot = DataLoader(test_data_onehot, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52353d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def train_full(rnn, training_data, labels, n_epoch = 10, n_batch_size = 64, report_every = 1, learning_rate = 0.2, criterion = nn.CrossEntropyLoss()):\n",
    "    \"\"\"\n",
    "    Learn on a batch of training_data for a specified number of iterations and reporting thresholds\n",
    "    \"\"\"\n",
    "    # Keep track of losses for plotting\n",
    "    current_loss = 0\n",
    "    all_losses = []\n",
    "    rnn.train()\n",
    "    optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"training on data set with n = {len(training_data)}\")\n",
    "\n",
    "    for iter in range(1, n_epoch + 1):\n",
    "        rnn.zero_grad() # clear the gradients\n",
    "\n",
    "        # create some minibatches\n",
    "        # we cannot use dataloaders because each of our names is a different length\n",
    "        batches = list(range(len(training_data)))\n",
    "        random.shuffle(batches)\n",
    "        batches = np.array_split(batches, len(batches) // n_batch_size)\n",
    "\n",
    "        for idx, batch in enumerate(batches):\n",
    "            batch_loss = 0\n",
    "            for i in batch: #for each example in this batch\n",
    "                input_tensor = nn.functional.one_hot(training_data[i], num_classes=len(onehot_dict) + 1)\n",
    "                output = rnn.forward(input_tensor.float())\n",
    "                loss = criterion(output[0], labels[i])\n",
    "                batch_loss += loss\n",
    "\n",
    "            # optimize parameters\n",
    "            batch_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(rnn.parameters(), 3)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            current_loss += batch_loss.item() / len(batch)\n",
    "\n",
    "        all_losses.append(current_loss / len(batches) )\n",
    "        if iter % report_every == 0:\n",
    "            print(f\"{iter} ({iter / n_epoch:.0%}): \\t average batch loss = {all_losses[-1]}\")\n",
    "        current_loss = 0\n",
    "\n",
    "    return all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5242aade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on data set with n = 11514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luanico/epita/nlp/venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1751: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (2%): \t average batch loss = 2.472912135350664\n",
      "2 (4%): \t average batch loss = 2.0011095451814263\n",
      "3 (6%): \t average batch loss = 1.731072054936337\n",
      "4 (8%): \t average batch loss = 1.513111670318655\n",
      "5 (10%): \t average batch loss = 1.369294754647092\n",
      "6 (12%): \t average batch loss = 1.2509069336537126\n",
      "7 (14%): \t average batch loss = 1.132591946528508\n",
      "8 (16%): \t average batch loss = 1.0469787386221234\n",
      "9 (18%): \t average batch loss = 0.9638640122493383\n",
      "10 (20%): \t average batch loss = 0.887567630407404\n",
      "11 (22%): \t average batch loss = 0.8108307805364351\n",
      "12 (24%): \t average batch loss = 0.7502864451264862\n",
      "13 (26%): \t average batch loss = 0.7109376229841177\n",
      "14 (28%): \t average batch loss = 0.6413598623514969\n",
      "15 (30%): \t average batch loss = 0.6138460411722452\n",
      "16 (32%): \t average batch loss = 0.5703275142385809\n",
      "17 (34%): \t average batch loss = 0.5215671843397978\n",
      "18 (36%): \t average batch loss = 0.4848785761423338\n",
      "19 (38%): \t average batch loss = 0.4632323901286491\n",
      "20 (40%): \t average batch loss = 0.43600795117508984\n",
      "21 (42%): \t average batch loss = 0.4068363917440075\n",
      "22 (44%): \t average batch loss = 0.3819349184973186\n",
      "23 (46%): \t average batch loss = 0.3550739323239665\n",
      "24 (48%): \t average batch loss = 0.32509772784255414\n",
      "25 (50%): \t average batch loss = 0.3177073841617258\n",
      "26 (52%): \t average batch loss = 0.2983053721121721\n",
      "27 (54%): \t average batch loss = 0.2823741994920784\n",
      "28 (56%): \t average batch loss = 0.27350093564560585\n",
      "29 (58%): \t average batch loss = 0.2502116251043653\n",
      "30 (60%): \t average batch loss = 0.2516862706934728\n",
      "31 (62%): \t average batch loss = 0.23660957794185467\n",
      "32 (64%): \t average batch loss = 0.22708417912450513\n",
      "33 (66%): \t average batch loss = 0.2194876633129989\n",
      "34 (68%): \t average batch loss = 0.2065002060506656\n",
      "35 (70%): \t average batch loss = 0.195918147849897\n",
      "36 (72%): \t average batch loss = 0.20133132896465192\n",
      "37 (74%): \t average batch loss = 0.17850548321885804\n",
      "38 (76%): \t average batch loss = 0.18418359107546592\n",
      "39 (78%): \t average batch loss = 0.18568136082116174\n",
      "40 (80%): \t average batch loss = 0.17036788447734513\n",
      "41 (82%): \t average batch loss = 0.16894095993331035\n",
      "42 (84%): \t average batch loss = 0.16105522598739858\n",
      "43 (86%): \t average batch loss = 0.15617101003942283\n",
      "44 (88%): \t average batch loss = 0.15375229988374225\n",
      "45 (90%): \t average batch loss = 0.14439217505766\n",
      "46 (92%): \t average batch loss = 0.134777665205524\n",
      "47 (94%): \t average batch loss = 0.13217428423030717\n",
      "48 (96%): \t average batch loss = 0.1253095622998863\n",
      "49 (98%): \t average batch loss = 0.12529158893127906\n",
      "50 (100%): \t average batch loss = 0.12606496146739926\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(len(onehot_dict) + 1, h_dim, 18)\n",
    "\n",
    "losses = train_full(rnn, [torch.tensor(x) for x in X_train_embeddings], torch.tensor(Y_train),n_batch_size=25, learning_rate=0.1, n_epoch=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "80ce0b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_full(rnn, testing_data, labels, labels_tensor, classes):\n",
    "    confusion = torch.zeros(len(classes), len(classes))\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    rnn.eval() #set to eval mode\n",
    "    with torch.no_grad(): # do not record the gradients during eval phase\n",
    "        for i in range(len(testing_data)):\n",
    "            input_tensor = nn.functional.one_hot(testing_data[i], num_classes=len(onehot_dict) + 1)\n",
    "            output = rnn(input_tensor.float())\n",
    "            guess_i = torch.argmax(output).item()\n",
    "            label_i = classes.index(labels[i])\n",
    "            confusion[label_i][guess_i] += 1\n",
    "            if guess_i == label_i:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    # Normalize by dividing every row by its sum\n",
    "    for i in range(len(classes)):\n",
    "        denom = confusion[i].sum()\n",
    "        if denom > 0:\n",
    "            confusion[i] = confusion[i] / denom\n",
    "\n",
    "    # Set up plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(confusion.cpu().numpy()) #numpy uses cpu here so we need to use a cpu version\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticks(np.arange(len(classes)), labels=classes, rotation=90)\n",
    "    ax.set_yticks(np.arange(len(classes)), labels=classes)\n",
    "\n",
    "    # Force label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    # sphinx_gallery_thumbnail_number = 2\n",
    "    plt.show()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "daaaeeac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation with rnn: accuracy = 0.7360457296570275\n"
     ]
    }
   ],
   "source": [
    "_SCENARIOS = ['social', 'transport', 'calendar', 'play', 'news', 'datetime', 'recommendation', 'email',\n",
    "              'iot', 'general', 'audio', 'lists', 'qa', 'cooking', 'takeaway', 'music', 'alarm', 'weather']\n",
    "\n",
    "#test_in =  nn.functional.one_hot(torch.LongTensor(X_test_embeddings[5]), num_classes=len(onehot_dict) + 1)\n",
    "#label_from_output(rnn(test_in.float()), list(range(18)))\n",
    "\n",
    "accuracy_rnn = evaluate_full(rnn, [torch.LongTensor(x) for x in X_test_embeddings], Y_test, torch.tensor(Y_test), list(range(18)))\n",
    "\n",
    "print(f\"Evaluation with rnn: accuracy = {accuracy_rnn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f25c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
