from nltk.tokenize import word_tokenize
import nltk
import pandas as pd
from nltk.corpus import stopwords
from typing import List, Tuple
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
from datasets import load_dataset
from submodels import train_on_class
from datetime import datetime

UWU_PHRASES = {
    "social": "UwU~ je suis ton chatbot social pweferÃ©, toujours wÃ  pour discuter avec twa nya~ (âœ¿Ëµâ—• â€¿ â—•Ëµ)",
    "transport": "Ohh, UwU! Besoin d'aide pour trouver un twain ou un bus? Je te guide avec plaisir nya~ ðŸš‹âœ¨",
    "calendar": "Nyaaa~ Tes wendez-vous sont tous beaux et bien rangÃ©s, veux-tu vÃ©rifier, chaton UwU? (âœ¿Ëµâ—• â€¿ â—•Ëµ)",
    "play": "UwU~ PrÃªte Ã  jouer ensemble! Que veux-tu essayer aujourdâ€™hui, hihi? ðŸŽ®âœ¨",
    "news": "OwO! Les derniÃ¨wes nouvelles? Je peux te les donner tout de suite, adorable lecteur UwU! ðŸ“°ðŸ’–",
    "datetime": f"Nyaww~ Il est actuellement {datetime.now()} si tu te demandais, petit chat UwU! (âœ¿Ëµâ—• â€¿ â—•Ëµ)",
    "recommendation": "Hihi UwU~ Laisse-moi te wÃ©commander des choses parfaites pour twa, mon chou! (â‰§â—¡â‰¦)",
    "email": "OwO~ Un email pour toi? Je peux t'aider Ã  le rÃ©diger, uwu rapide comme un petit Ã©clair âœ‰ï¸âœ¨",
    "iot": "UwU~ Je peux allumer tes wumiÃ¨res ou rÃ©gler ta maison connectÃ©e nyah! ðŸŒŸ (âœ¿Ëµâ—• â€¿ â—•Ëµ)",
    "general": "Nyahaha~ Demande ce que tu veux, je suis lÃ  pour twa UwU~ ðŸ’¬âœ¨",
    "audio": "OwO~ Tu veux entendre un son ou de la musique? UwU Je suis prÃªte! ðŸŽµðŸ’•",
    "lists": "UwU~ Ta wiste est prÃªte! Dis-moi ce que tu veux ajouter, hihi~ ðŸ“‹âœ¨",
    "qa": "Nyuu~ Pose-moi une qwestion, je vais tout faire pour y rÃ©pondre adorablement UwU~ ðŸ’¡",
    "cooking": "UwU~ On cuisine ensemble? Je trouve des recettes pour twa, hihi~ ðŸ³ðŸ’–",
    "takeaway": "OwO~ Commande Ã  emporter? Je peux t'aider Ã  choisir, nyah~ ðŸ”âœ¨",
    "music": "UwU~ Une chanson pour twa? Je lance Ã§a tout de suite, hihi~ ðŸŽ¶ðŸ’–",
    "alarm": "Nyaa~ RÃ©veil programmÃ©! Je vais miauler pour twa quand il sonnera UwU~ â°âœ¨",
    "weather": "UwU~ Le temps est magnifique aujourdâ€™hui! Je te donne les dÃ©tails si tu veux~ ðŸŒ¤ï¸ (âœ¿Ëµâ—• â€¿ â—•Ëµ)",
}


def main():
    nltk.download("punkt_tab")
    nltk.download("stopwords")

    ds = load_dataset("AmazonScience/massive", "fr-FR")
    class_name = "scenario"
    sub_class_name = "intent"
    scenario_decoder = ds["train"].features[class_name].int2str
    intent_decoder = ds["train"].features[sub_class_name].int2str

    # Access intent list
    intent_list = ds["train"].features[class_name].names
    print(intent_list)

    # model already tokenizes
    X_train = ds["train"]["utt"]
    y_train = ds["train"][class_name]

    vectorizer = CountVectorizer()
    X_train_bow = vectorizer.fit_transform(X_train)

    # Train on each sub class
    class_list = ds["train"].features[class_name].names
    intent_models = {}
    for i in range(len(class_list)):
        (intent_vectorizer, intent_clf) = train_on_class(ds, i)
        intent_models[i] = (intent_vectorizer, intent_clf)

    # Train NaÃ¯ve Bayes classifier
    clf = MultinomialNB()
    clf.fit(X_train_bow, y_train)

    # Test with a custom input
    test_vectorizer, test_clf = vectorizer, clf
    while True:
        user_input = input(
            "\nEntwe une fwhase Ã  cwassifier, s'il te pwait, nya~ ðŸ’–\n> "
        )
        _, _, scenario_n = predict_scenario(user_input, vectorizer, clf)
        test_vectorizer, test_clf = intent_models[scenario_n]
        label_str = scenario_decoder(int(scenario_n))

        # Enter a phrase and print result
        (klass, proba, intent_n) = predict_scenario(
            user_input, test_vectorizer, test_clf
        )
        print(UWU_PHRASES[label_str])
        print(f"proba: {proba}")


def predict_scenario(
    text: str, vectorizer: CountVectorizer, model: MultinomialNB
) -> Tuple[int, float]:
    """
    Preprocesses input text, vectorizes it, and predicts the scenario.
    returns: (class_index, confidence)
    """
    text_bow = vectorizer.transform([text])  # Convert to BoW
    probabilities = model.predict_proba(text_bow)[0]
    klass = probabilities.argmax()
    print(probabilities)
    proba = probabilities[klass]
    proba = round(proba * 100, 3)

    intent_number = model.classes_[klass]
    return klass, proba, intent_number


if __name__ == "__main__":
    main()
